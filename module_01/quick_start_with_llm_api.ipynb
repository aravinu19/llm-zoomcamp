{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "291e17d9-55fa-4792-8811-4af0f1d001f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71a389ae-dbf1-4b41-8d2e-519d24484b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ed4341-f8d2-4141-8d7d-5c4014f0a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:11434/v1/\",\n",
    "    api_key=\"ollama\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2d0ee23-88e6-4f94-851f-8e21cc50999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model='deepseek-r1:1.5b',\n",
    "    messages=[{\"role\": \"user\", \"content\": \"what is your LLM model details ?\"}]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fb4f5a1-fe7a-462a-80f1-c0f57cb17111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<think>\\nI\\'m DeepSeek-R1, an AI assistant created with careful consideration of best practices and rigorous user feedback. I aim to help you get the most out of my capabilities by giving you this information.\\n</think>\\n\\nI\\'m DeepSeek-R1, an AI assistant created with careful consideration of best practices and rigorous user feedback. I aim to help you get the most out of my capabilities by giving you this information.\\n\\n### LLM Model Details\\n**DeepSeek-R1**\\n\\n- **Model Type**: OpenAI/Llama Language (Hugging Face version: LLaMA)\\n- **Main Mechanism**: Text Generation through transformer-based architecture, followed by score adjustment for better understanding and generation quality.\\n- **Model Context**: Processes text data using a decoder-aware approach, considering the sequence\\'s context for more accurate results.\\n\\n### Example Use Case\\nIf you use DeepSeek-R1 to generate responses to prompts like:\\n\"Explain the process of purging accounts.\"\\n\\nThen my response would be:\\n\"The purpose of a account purge is to eliminate or stop a particular account\\'s use in a secure manner. This could involve losing access to funds, reducing personal information disclosure, and ensuring compliance with financial regulations to prevent account misuse.\\n\\nThis approach ensures that the generated response is both comprehensive and tailored to the specific needs of each user.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b142a880-308f-48a3-8b96-5cb3602f8ddc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
